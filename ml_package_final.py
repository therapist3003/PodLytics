# -*- coding: utf-8 -*-
"""ML_package_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19iqjALi3ueUEKBZbLEnsTa4b0BwRKjjd
"""

pip install vadersentiment

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from collections import defaultdict
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve
import numpy as np

n_key = 5  # no of words to be considered for BoW (bag of words for each category...if increased then more accurate prediction may be seen)

# Load the dataset
data = pd.read_csv('/content/shows.csv')

# Filter out rows with NaN values in 'description' and 'category'
data.dropna(subset=['description', 'category'], inplace=True)

# Create a mapping from category to keywords
category_keywords = defaultdict(list)

# Group descriptions by category and extract frequent keywords
for category, group in data.groupby('category'):
    all_descriptions = " ".join(group['description'].astype(str).str.lower())
    vectorizer = CountVectorizer()
    X = vectorizer.fit_transform([all_descriptions])
    word_counts = list(zip(vectorizer.get_feature_names_out(), X.toarray()[0]))
    word_counts.sort(key=lambda x: x[1], reverse=True)

    # Add top N keywords to the category_keywords dictionary
    top_n_keywords = [word for word, count in word_counts[:n_key]]
    category_keywords[category] = top_n_keywords

# Create training data with category labels
X = data["description"]
y = data["category"]

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a Naive Bayes classifier
classifier = MultinomialNB()

# Build the pipeline
model = Pipeline([
    ("vectorizer", CountVectorizer()),
    ("classifier", classifier)
])

# Train the model
model.fit(X_train.astype(str).str.lower(), y_train)

# Predict the category for a new description
new = input("Enter the new description to predict its category: ")
new_description = [new]
predicted_category = model.predict(new_description)

# Print the heatmap of the confusion matrix
y_pred = model.predict(X_test)
conf_matrix = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()
plt.savefig('confusionmatrix.jpg')

# Compute the ROC curve for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
probs = model.predict_proba(X_test)

for i, category in enumerate(model.classes_):
    fpr[i], tpr[i], _ = roc_curve((y_test == category).astype(int), probs[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(8, 6))
for i, category in enumerate(model.classes_):
    plt.plot(fpr[i], tpr[i], label=f'ROC curve ({category}) (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc="lower right")
plt.show()
plt.savefig('roc_curve.jpg')

# Compute precision and recall for each class
precision = dict()
recall = dict()
pr_auc = dict()

for i, category in enumerate(model.classes_):
    precision[i], recall[i], _ = precision_recall_curve((y_test == category).astype(int), probs[:, i])
    pr_auc[i] = auc(recall[i], precision[i])

plt.figure(figsize=(8, 6))
for i, category in enumerate(model.classes_):
    plt.plot(recall[i], precision[i], label=f'PR curve ({category}) (AUC = {pr_auc[i]:.2f})')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()
plt.savefig('precision_recall.jpg')

print("Predicted Category:", predicted_category[0])
print("Category Keywords:", category_keywords[predicted_category[0]])

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# 1. Load the dataset and remove specified columns
data = pd.read_csv("poddata.tsv", delimiter="\t")
columns_to_remove = [
    'show_filename_prefix',
    'episode_filename_prefix',
    'rss_link',
    'episode_uri',
    'publisher',
    'language',
    'show_uri',
    'duration'
]
data = data.drop(columns=columns_to_remove)
data = data.dropna(subset=['episode_description'])

# 2. Initialize Sentiment Analyzer
analyzer = SentimentIntensityAnalyzer()

# 3. Analyze Sentiment and Create a "sentiment" Column
def analyze_sentiment(description):
    sentiment_score = analyzer.polarity_scores(description)
    if sentiment_score['compound'] >= 0:
        return 'positive'
    else:
        return 'negative'

data['sentiment'] = data['episode_description'].apply(analyze_sentiment)
# Count the number of positive and negative sentiments
sentiment_counts = data['sentiment'].value_counts()

# Plot the sentiment distribution
plt.figure(figsize=(8, 6))
plt.bar(sentiment_counts.index, sentiment_counts.values)
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.title('Sentiment Distribution')
plt.show()
# 4. Print an Equal Number of Positive and Negative Records
positive_records = data[data['sentiment'] == 'positive'].head(15)
negative_records = data[data['sentiment'] == 'negative'].head(15)
balanced_data = pd.concat([positive_records, negative_records])

# 5. Print the balanced data
print(balanced_data[['episode_description', 'sentiment']])

